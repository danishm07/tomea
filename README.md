
### Tomea


**Autonomous Research Implementation Engine**

Tomea is an experimental framework that automates the implementation of Machine Learning research papers. It reads raw arXiv papers, synthesizes PyTorch code (adapters, layers, training loops), and executes them in a self-healing environment that autonomously fixes runtime errors (tensor shape mismatches, CUDA issues, etc.).

**Status: Pre-Alpha / Prototype**
*This repository is a work-in-progress research artifact. It is designed for experimentation with agentic orchestration, not production deployment.*

## Features
* **Paper-to-Code:** Parses arXiv PDFs and generates `nn.Module` implementations.
* **Self-Healing Engine:** Diagnoses stack traces (e.g., `RuntimeError`) and hot-patches the Python code to fix bugs during training.
* **Cloud Execution:** Spins up ephemeral GPU containers via [Modal](https://modal.com) to run experiments in parallel.
* **TUI Dashboard:** Real-time terminal dashboard for tracking loss curves and agent status.

## Quick Start

### Prerequisites
* Python 3.10+
* A [Modal](https://modal.com) account (for GPU execution)
* An LLM API Key (OpenRouter, OpenAI, or Anthropic)

### Installation

1. **Clone the repository:**
   ```bash
   git clone [https://github.com/yourusername/tomea.git](https://github.com/yourusername/tomea.git)
   cd tomea

   ```

2. **Setup Virtual Environment:**
   ```bash
   python3 -m venv .venv
   source .venv/bin/activate
   pip install -r requirements.txt
   
   ```


3. **Configure Secrets:**
Create a `.env` file in the root directory:
```bash
OPENROUTER_API_KEY=sk-or-your-key-here
# Optional:
# OPENAI_API_KEY=...


```


4. **Setup Modal:**
This project uses Modal for serverless GPU execution. Authenticate your client:
```bash
modal setup

```



### Usage

Run the demo engine to start an interactive session. You can select a dataset and a list of papers (Standard or Custom ArXiv ID).

```bash
python demo_engine.py

```

*The engine will:*

1. *Read the paper.*
2. *Generate the `adapter.py` file.*
3. *Launch a training run on Modal.*
4. *If the run crashes, the **Healer** will attempt to fix the code and restart.*

## Project Structure

* `tomea/agents`: **Synthesizer** (The LLM that writes code) & Healer logic.
* `tomea/core`: **Engine** logic (The loop that manages retry/heal cycles).
* `tomea/engine`: **Executor** (Modal integration and remote logging).
* `tomea/ui`: **Dashboard** (Rich-based TUI).
* `tomea/utils`: Artifact managers and paper parsers.

## License

This project is licensed under the MIT License - see the [LICENSE](https://www.google.com/search?q=LICENSE) file for details.

## Disclaimer

This tool executes code generated by an LLM on your local machine or cloud account. While it runs in a sandboxed environment (Modal), you may want to review generated code before execution. Use at your own risk.



---

